name: Scraper

on:
  schedule:
    - cron: '15 0 * * *'
  workflow_dispatch:

concurrency:
  group: workflow-group
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 700

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright for Python
        run: |
          python -m pip install playwright
          python -m playwright install

      - name: Verify Files and Secrets
        run: |
          ls -la
          echo "OOGOO_GCLOUD_KEY_JSON is ${{ secrets.OOGOO_GCLOUD_KEY_JSON }}"

      - name: Create Deploy Script (if missing)
        run: |
          if [ ! -f ./deploy.sh ]; then
            echo "Creating deploy.sh..."
            echo '#!/bin/bash' > deploy.sh
            echo 'echo "Running deployment with provided secret..."' >> deploy.sh
            chmod +x deploy.sh
          fi

      - name: Deploy Application
        run: ./deploy.sh ${{ secrets.OOGOO_GCLOUD_KEY_JSON }}

      - name: Run the scraper
        env:
          OOGOO_GCLOUD_KEY_JSON: ${{ secrets.OOGOO_GCLOUD_KEY_JSON }}
        run: |
          python main.py

      - name: Cleanup
        run: echo "Cleanup complete"
