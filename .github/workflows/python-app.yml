name: Scraper Workflow

on:
  schedule:
    - cron: '15 0 * * *' # Runs every day
  workflow_dispatch:  # Allows manual triggering
  
concurrency:
  group: workflow-group
  cancel-in-progress: true
  
jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 700

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Install Playwright for Python
        run: |
          python -m pip install --upgrade pip
          pip install playwright
          python -m playwright install
      - name: Fix PhantomJS Issue
        run: |
          npm uninstall phantomjs-prebuilt
          npm install phantomjs-prebuilt@2.1.13
          npm cache clear --force
          npm install

      - name: Run the scraper
        env:
          OOGOO_GCLOUD_KEY_JSON: ${{ secrets.OOGOO_GCLOUD_KEY_JSON }}
        run: |
          python main.py
      
      - name: Print environment variables (for debugging)
        run: echo $OOGOO_GCLOUD_KEY_JSON
      
      - name: Cleanup
        run: |
          # Any cleanup steps (optional)
